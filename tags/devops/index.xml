<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>DevOps on Coding Blog By Arnab Kumar Shil</title><link>https://ruddra.com/tags/devops/</link><description>Recent content in DevOps on Coding Blog By Arnab Kumar Shil</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Thu, 16 Apr 2020 20:19:01 +0600</lastBuildDate><atom:link href="https://ruddra.com/tags/devops/index.xml" rel="self" type="application/rss+xml"/><item><title>Run a Build in AWS CodeBuild When a Git Tag is Pushed</title><link>https://ruddra.com/aws-codebuild-use-git-tags/</link><pubDate>Thu, 16 Apr 2020 20:19:01 +0600</pubDate><guid>https://ruddra.com/aws-codebuild-use-git-tags/</guid><description>AWS CodeBuild has nice integration with different Git repository hosting service providers(like GitHub, BitBucket, even amazon&amp;rsquo;s own CodeCommit etc). Even using WebHook is pretty easy. You can start a build in CodeBuild for every push, pull, PR created, PR merged etc. But it can be bit tricky when it comes to trigger for every tag push only, as it us not a default event type provided by CodeBuild.</description></item><item><title>Ship Application with Database Inside Docker Container</title><link>https://ruddra.com/docker-ship-database-with-container/</link><pubDate>Fri, 28 Feb 2020 00:53:28 +0600</pubDate><guid>https://ruddra.com/docker-ship-database-with-container/</guid><description>DISCLAIMER: This is not the recommended process. Ideally you should have the database running in a separate container and use network to interact with that container.
Usually, we donâ€™t ship application with the database inside the same container. But sometimes we are forced to do that. In this article we are going to see a minimalist way of shipping application with database built-in inside docker container.</description></item><item><title>Use Docker for Accessing Database in AWS CodeBuild</title><link>https://ruddra.com/aws-codebuild-use-database/</link><pubDate>Fri, 31 Jan 2020 19:08:29 +0600</pubDate><guid>https://ruddra.com/aws-codebuild-use-database/</guid><description>AWS CodeBuild is an extraordinary tool for building your code. Recently I have been using it to build projects and store docker images in AWS ECR. During those CodeBuild processes, I needed Database for running tests. As the need of the Database was for a limited time and I didn&amp;rsquo;t want to pay extra for it(that is why I did not use AWS RDS), I decided to create database using docker inside CodeBuild.</description></item><item><title>How to Use Volume, Entrypoint and Ignore Files in Docker</title><link>https://ruddra.com/docker-volume-entrypoint-ignorefile/</link><pubDate>Sat, 09 Nov 2019 00:56:04 +0600</pubDate><guid>https://ruddra.com/docker-volume-entrypoint-ignorefile/</guid><description>Have you worked with Docker before? Do you think you have trouble with it, like when you are developing an application, you need to build every time to see the results, or thinking of the best way to load data in DB, or may be you are annoyed because there are lots of markdown files, screenshots etc that are taking a lot of space in your container.</description></item><item><title>Why Use Docker Compose, Build Argument and Environment Variable</title><link>https://ruddra.com/docker-compose-arg-env/</link><pubDate>Sat, 09 Nov 2019 00:00:00 +0600</pubDate><guid>https://ruddra.com/docker-compose-arg-env/</guid><description>Imagine, you have some microservices and you want to use API from one service to another, how can you do that if all of them are running in different docker container? Docker Compose has a solution for you.
Suppose you want to deploy a project in test, stage and production environment with same Dockerfile for all of them through a single Dockerfile.</description></item><item><title>How to Write Dockerfile to Reduce Size and Build Time of Docker Images</title><link>https://ruddra.com/docker-write-dockerfile-and-reduce-size-build-time-for-image/</link><pubDate>Fri, 08 Nov 2019 00:15:22 +0600</pubDate><guid>https://ruddra.com/docker-write-dockerfile-and-reduce-size-build-time-for-image/</guid><description>For the past couple of years, I have been creating Dockerfile for different projects. based on those experiences I am going to share some tips on writing docker files to communication between containers.
_FYI: before reading this article, please read the article from official docker blog site to learn about best practices for creating Dockerfile.</description></item><item><title>Deploy Django App in Sub Directory Using OpenShift</title><link>https://ruddra.com/deploy-django-subpath-openshift/</link><pubDate>Wed, 24 Apr 2019 20:36:44 +0600</pubDate><guid>https://ruddra.com/deploy-django-subpath-openshift/</guid><description>When you are using OpenShift, you will be using routes to expose a route from a service. Let&amp;rsquo;s say you want to expose a path in example.com/dummy. When you do that for a django application(without any reverse proxy server), it usually becomes a problem, because the sub directory does not work well with Django&amp;rsquo;s urls.</description></item><item><title>Do Extra in S3 Using Django Storage and Boto3</title><link>https://ruddra.com/aws-boto3-useful-functions/</link><pubDate>Sat, 06 Apr 2019 01:49:10 +0600</pubDate><guid>https://ruddra.com/aws-boto3-useful-functions/</guid><description>Today, I am going to write about few useful snippets/functionalities which I have used for Amazon S3 or any S3 compitable storage using Boto3 and Django Storage. FYI, this post focuses on using S3 with Django.
So without further ado, let us begin. Table of contents&amp;nbsp; Configuring S3 Using S3 which it does not belong to AWS Serve S3 in different domain(through cloudFront or varnish) Create new bucket See all buckets Change access control to a bucket Delete objects from a bucket(also bucket itself) Use different folders when storing media and static contents Make &amp;lsquo;collect static&amp;rsquo; faster Check ACL status In conclusion</description></item><item><title>Automated Deployment to OpenShift Using Jenkins and Webhook</title><link>https://ruddra.com/openshift-python-pipeline-deployment/</link><pubDate>Sun, 12 Aug 2018 16:45:42 +0000</pubDate><guid>https://ruddra.com/openshift-python-pipeline-deployment/</guid><description>The last post was about defining the pipelines. Now it is time to execute them. Also, at the end, we are going to show how to integrate webhook in your repository, so that for a specific event(like Push, Pull request merge etc) it will trigger the pipelines to automatically deploy the latest code to servers.</description></item><item><title>Writing Jenkins Pipeline For OpenShift Deployment: Part Two</title><link>https://ruddra.com/openshift-python-jenkins-pipeline-two/</link><pubDate>Sat, 11 Aug 2018 20:41:04 +0000</pubDate><guid>https://ruddra.com/openshift-python-jenkins-pipeline-two/</guid><description>In previous article, we covered step 1-5 which would prepare the code and make sure it is ready to be deployed to OpenShift. Now we are going to use the next steps to deploy that code.Table of contents&amp;nbsp; Step 6: create build configuration in OpenShift Step 7: build image Step 8: deploy to OpenShift in DEV Step 9: promote image to STAGE Step 10: deploy to OpenShift in STAGE Step 11: scale in STAGE Conclusion</description></item><item><title>Writing Jenkins Pipeline For OpenShift Deployment: Part One</title><link>https://ruddra.com/openshift-python-jenkins-pipeline-one/</link><pubDate>Sat, 11 Aug 2018 19:41:04 +0000</pubDate><guid>https://ruddra.com/openshift-python-jenkins-pipeline-one/</guid><description>Pipeline is a set of instructions, which will be executed as per given sequence and produce a output. Jenkins Pipeline is simply writing these instructions in Jenkins. These pipelines can be written in Groovy.
In previous post we have defined deployment structure and made necessary preparations for deployment of a python+gunicorn+nginx+jenkins based project.</description></item><item><title>Deploy A Python App to OpenShift: Planning and Preparations</title><link>https://ruddra.com/openshift-python-pipeline-preparation/</link><pubDate>Sat, 11 Aug 2018 15:09:01 +0000</pubDate><guid>https://ruddra.com/openshift-python-pipeline-preparation/</guid><description>Deploying a Python application to OpenShift is fairly easy. Write a Dockerfile and run oc new-app /path/to/Dockerfile, that&amp;rsquo;s it!! But if you want implement a full fledged modern CI/CD using Jenkins and openshift, you need to do little more than that. So let&amp;rsquo;s dive into it.
We will explain about the whole process in three articles:</description></item><item><title>Deploy Django to OpenShift 3 Powered by MySQL and Gunicorn</title><link>https://ruddra.com/deploy-django-to-openshift-3/</link><pubDate>Sat, 24 Feb 2018 13:32:11 +0000</pubDate><guid>https://ruddra.com/deploy-django-to-openshift-3/</guid><description>If you want to use OpenShift for deploying Django, you can follow this post and simply do that. You don&amp;rsquo;t need to learn Kubernetes. We will use docker file only. No other fancy stuff.
Also, before starting, I am also hoping you are little bit familiar with OpenShift 3 and oc tools.</description></item><item><title>Serve Static Files by Nginx from Django using Docker</title><link>https://ruddra.com/serve-static-files-by-nginx-from-django-using-docker/</link><pubDate>Wed, 02 Nov 2016 17:24:56 +0000</pubDate><guid>https://ruddra.com/serve-static-files-by-nginx-from-django-using-docker/</guid><description>This is more of a follow up post of my previous article.
Before I start, I am assuming you have successfully deployed django using docker and nginx, but having some problems serving static files.Table of contents&amp;nbsp; Steps Update
Steps No worries, it is easy. Just follow these steps:</description></item><item><title>Perodic Tasks By Celery 3.1 Example</title><link>https://ruddra.com/perodic-tasks-by-celery-3-1-example/</link><pubDate>Mon, 01 Sep 2014 18:03:07 +0000</pubDate><guid>https://ruddra.com/perodic-tasks-by-celery-3-1-example/</guid><description>This post is deprecated. It is no longer compatible with latest Celery versions.
I am assuming you have read celery docs from Celery Documentation.
As we know, celery can be used as a scheduler for executing asynchronous tasks in periodic cycles. Here I am going to share to do that with a code example.</description></item></channel></rss>
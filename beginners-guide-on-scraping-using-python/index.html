<!doctype html><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta charset="utf-8"><meta name="author" content="Arnab Kumar Shil"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="theme-color" content="#000000"><meta property="fb:app_id" content="668971647169067"><link rel="manifest" href="/manifest.json" crossorigin="use-credentials"><meta name="yandex-verification" content="3ccce49727df78e2"><link rel="copyright" href="https://ruddra.com/beginners-guide-on-scraping-using-python/#copyright"><link rel="article:author" href="https://ruddra.com/about/"><meta name="robots" content="index,follow"><meta name="referrer" content="unsafe-url"><meta property="og:url" content="https://ruddra.com/beginners-guide-on-scraping-using-python/"><meta name="keywords" content="Python,Scraping,Blog"><title>Beginner's Guide on Web Scraping using Python</title><meta name="description" content="When it comes to web scraping, you have to keep in mind that it is not the coding skill rather cunning observations will get you results. Sometimes the …"><link rel="preload" as="font" type="font/woff2" href="/fonts/merriweather-v21-latin-regular.woff2" crossorigin><link rel="preload" as="font" type="font/woff2" href="/fonts/pt-sans-v11-latin-regular.woff2" crossorigin><link rel="preload" as="font" type="font/woff2" href="/fonts/merriweather-v21-latin-700.woff2" crossorigin><meta name="twitter:label1" value="Reading time"><meta name="twitter:data1" value="7 Minutes"><style type="text/css">@font-face{font-family:pt sans;font-style:normal;font-weight:400;font-display:swap;src:url(/fonts/pt-sans-v11-latin-regular.eot);src:local("PT Sans"),local("PTSans-Regular"),url(/fonts/pt-sans-v11-latin-regular.eot?#iefix) format("embedded-opentype"),url(/fonts/pt-sans-v11-latin-regular.woff2) format("woff2"),url(/fonts/pt-sans-v11-latin-regular.woff) format("woff"),url(/fonts/pt-sans-v11-latin-regular.ttf) format("truetype"),url(/fonts/pt-sans-v11-latin-regular.svg#PTSans) format("svg")}*{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}a{text-decoration:none;padding:2px}body,html{margin:0;padding:0;scroll-behavior:smooth}body{color:#222;background-color:#fff;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%}.masthead{border-bottom:1px solid #eee;padding-top:1rem;padding-bottom:1rem;margin-bottom:3rem;background:#202020}.masthead-title{margin-top:0;margin-bottom:0;color:#505050;font-size:20px;letter-spacing:-.025rem;line-height:1.25}.homepage-title a,.masthead-title a{color:#505050;padding:0}.masthead-title small{font-size:75%;font-weight:400;color:silver;letter-spacing:0}h3{font-family:pt sans,Helvetica,Arial,sans-serif;font-weight:400}.container{max-width:42.5rem;padding-left:1rem;padding-right:1rem;margin-left:auto;margin-right:auto}.content{visibility:hidden}.sidebar{display:none}.sidebar-checkbox{display:none}#snackbar{display:none}.masthead-search-form{display:none}.sidebar-toggle{display:none}.masthead .homepage-title .home-title,.masthead .masthead-title .home-title{color:#cfcdcd}.masthead .homepage-title .home-title-small,.masthead .masthead-title .home-title-small{color:#8c8585;font-size:1.25rem;letter-spacing:-.25px}.homepage-title{margin:0;font-size:20px;line-height:1.25;letter-spacing:-.025rem;font-family:pt sans,Helvetica,Arial,sans-serif;font-weight:400}@media only screen and (min-width:38em){.container{max-width:32rem}}@media only screen and (min-width:30.1em){.container{max-width:28rem}}@media only screen and (min-width:56em){.container{max-width:42rem}}@media screen and (max-width:48em){.masthead-search-form{display:none}.homepage-title,.masthead-title{text-align:center}}</style><link rel="preload" href="/js/bundle1.min.78c0bdad978fe83d0f0ce27a8e61cf8cc1b5acfccc2a9b20bcd3e1bc610e9e68.js" as="script"><link rel="preload" href="/css/bundle.min.css" as="style"><link rel="stylesheet" href="/css/bundle.min.css" media="print" onload='this.media="all",this.onload=null'><noscript><link rel="stylesheet" href="/css/bundle.min.css"></noscript><link rel="amphtml" type="text/html" href="https://ruddra.com/amp/beginners-guide-on-scraping-using-python/"><link rel="preconnect" href="https://www.google-analytics.com"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon.png"><link rel="shortcut icon" href="/favicon.ico"><link rel="icon" href="https://ruddra.com/logo.png"><link rel="alternate" type="application/rss+xml" title="RSS" href="/sitemap.xml"><link rel="search" href="/opensearch.xml" title="Search at Ruddra" type="application/opensearchdescription+xml"><meta name="generator" content="Hugo 0.75.1"><meta name="twitter:card" content="summary_large_image"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="Coding Blog by Arnab Kumar Shil"><meta property="article:publisher" content="https://ruddra.com"><meta property="article:section" content="Bulletin"><meta property="article:published_time" content="2020-11-12T00:00:00.00Z"><meta property="article:modified_time" content="2020-11-13T00:00:00.00Z"><meta property="og:updated_time" content="2020-11-13T00:00:00.00Z"><meta property="og:image" content="https://ruddra.com/content/images/2020/11/crawling.jpg"><meta property="og:image:secure_url" content="https://ruddra.com/content/images/2020/11/crawling.jpg"><meta name="revised" content="Ruddra.com, 05/07/13116"><meta property="og:image:width" content="720"><meta property="og:image:height" content="350"><meta name="twitter:site" content="@ruddra"><meta name="twitter:creator" content="@ruddra"><meta name="twitter:title" content="Beginner's Guide on Web Scraping using Python"><meta name="twitter:description" content="When it comes to web scraping, you have to keep in mind that it is not the coding skill rather cunning observations will get you results. Sometimes the …"><meta property="og:type" content="Article"><meta property="og:title" content="Beginner's Guide on Web Scraping using Python"><meta property="og:description" content="When it comes to web scraping, you have to keep in mind that it is not the coding skill rather cunning observations will get you results. Sometimes the …"><meta name="twitter:image" content="https://ruddra.com/content/images/2020/11/crawling.jpg"><meta name="twitter:image:src" content="https://ruddra.com/content/images/2020/11/crawling.jpg"><meta property="article:tag" content="python"><meta property="article:tag" content="scraping"><meta property="article:tag" content="ruddra"><script type="application/ld+json">{"@context":"http://schema.org","@type":"NewsArticle","identifier":"beginners-guide-on-scraping-using-python","headline":"Beginner\u0027s Guide on Web Scraping using Python","keywords":["Python","Scraping","Blog"],"url":"https:\/\/ruddra.com\/beginners-guide-on-scraping-using-python\/","dateCreated":"2020-11-12T00:00:00.00Z","datePublished":"2020-11-12T00:00:00.00Z","dateModified":"2020-11-13T00:00:00.00Z","articleBody":"When it comes to web scraping, you have to keep in mind that it is not the coding skill rather cunning observations will get you results. Sometimes the data you get comes in a straight forward …","mainEntityOfPage":"https:\/\/ruddra.com\/beginners-guide-on-scraping-using-python\/","image":{"@type":"ImageObject","url":"https:\/\/ruddra.com\/content\/images\/2020\/11\/crawling.jpg","height":300,"width":750},"creator":["Arnab Kumar Shil"],"author":{"@type":"Person","name":"Arnab Kumar Shil","url":"https://ruddra.com"},"wordCount":"1309","commentCount":"0","copyrightYear":"2020","discussionUrl":"https:\/\/ruddra.com\/beginners-guide-on-scraping-using-python\/#comment-headline","isFamilyFriendly":"true","maintainer":{"@type":"Person","name":"Arnab Kumar Shil","url":"https://ruddra.com"},"publisher":{"@type":"Organization","name":"Coding Blog by Arnab Kumar Shil","url":"https://ruddra.com","logo":{"@type":"ImageObject","url":"https:\/\/ruddra.com\/logo.png"}},"thumbnailUrl":"https:\/\/ruddra.com\/content\/images\/2020\/11\/crawling.jpg"}</script></head><body><input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox"><div class="sidebar" id="sidebar"><div class="sidebar-item"><img data-src="/avatar.jpg" src="data:image/jpeg;base64,/9j/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2MBERISGBUYLxoaL2NCOEJjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY//AABEIABQAFAMBIgACEQEDEQH/xAGiAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgsQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+gEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoLEQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/AK2quHuEbGMHq23n5T/hVHTj9qnESPG+MsoLEYGCcVc8XXzSWUMIjRQz5JVjxgf/AF65q1ne2uI5ocb1YHHr7Vmk7GraudimnX+0FbXcDyOR/iKd/Z+o/wDPn+o/xqy7ozZMAJ9QoNN3R/8APuP++K5+Z9jYxtXUPYMGzhWJHPopNZnhaCO5163SVdy/Mce4UkfyrU1T/jxk+rf+gNWf4O/5GK3+jf8AoJrqRhLc78wRDjywcevNHkxf88k/KpH+9SUrILn/2Q==" class="lozad" alt="avatar" width="175px" height="175px"><p class="sidebar-item-bio">I am Arnab, a full stack developer specializing in <a href="https://ruddra.com/tags/python">Python</a>, <a href="https://ruddra.com/tags/django">Django</a>, <a href="https://ruddra.com/tags/react">React</a>, <a href="https://ruddra.com/tags/docker">Docker</a>, <a href="https://ruddra.com/tags/openshift">OpenShift</a>. A top <a href="https://stackoverflow.com/users/story/2696165">1%</a> contributor at Stack Overflow.</p><p class="sidebar-icons"><a class="icon-side-bar" href="https://facebook.com/ruddra.blog/" target="_blank" rel="noopener me" title="facebook"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-facebook"><path d="M18 2h-3a5 5 0 00-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 011-1h3z"/></svg></a><a class="icon-side-bar" href="https://twitter.com/ruddraarnab" target="_blank" rel="noopener me" title="twitter"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a><a class="icon-side-bar" href="https://www.linkedin.com/in/ruddraarnab" target="_blank" rel="noopener me" title="linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-linkedin"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a><a class="icon-side-bar" href="https://github.com/ruddra" target="_blank" rel="noopener me" title="github"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77a5.44 5.44.0 00-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a><a class="icon-side-bar" href="https://stackoverflow.com/users/2696165/ruddra" target="_blank" rel="noopener me" title="stackoverflow"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="10 10 100 100" fill="currentcolor" class="feather"><path d="M84.4 93.8V70.6h7.7v30.9H22.6V70.6h7.7v23.2z"/><path d="M38.8 68.4l37.8 7.9 1.6-7.6-37.8-7.9-1.6 7.6zm5-18 35 16.3 3.2-7-35-16.4-3.2 7.1zm9.7-17.2 29.7 24.7 4.9-5.9-29.7-24.7-4.9 5.9zm19.2-18.3-6.2 4.6 23 31 6.2-4.6-23-31zM38 86h38.6v-7.7H38V86z"/></svg></a></p></div><nav class="sidebar-nav"><a class="sidebar-nav-item" href="/">Home</a> <a class="sidebar-nav-item" href="/posts/">All Posts</a> <a class="sidebar-nav-item" href="/about/">About Me</a> <a class="sidebar-nav-item" href="/privacy/">Privacy Policy</a> <a class="sidebar-nav-item" href="/contact/">Contact Me</a><form target="_top" class="sidebar-nav-item search-form" method="get" action="/search/"><input type="text" placeholder="Search ..." aria-label="search" class="tftextinput" name="q" size="21" maxlength="120"><button type="submit" aria-label="search button" class="tfbutton"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="rgb(155,155,155)"><path d="M9.145 18.29c-5.042.0-9.145-4.102-9.145-9.145S4.103.0 9.145.0s9.145 4.103 9.145 9.145-4.102 9.145-9.145 9.145zm0-15.167c-3.321.0-6.022 2.702-6.022 6.022s2.702 6.022 6.022 6.022 6.023-2.702 6.023-6.022-2.702-6.022-6.023-6.022zm9.263 12.443c-.817 1.176-1.852 2.188-3.046 2.981l5.452 5.453 3.014-3.013-5.42-5.421z"/></svg></button></form></nav><div class="sidebar-item" id="copyright"><p>&copy; 2020 Arnab Kumar Shil &#183; <a href="/index.xml"><svg class="rss-feed" xmlns="http://www.w3.org/2000/svg" width="10" height="9" viewBox="0 0 24 24"><path d="M6.503 20.752c0 1.794-1.456 3.248-3.251 3.248-1.796.0-3.252-1.454-3.252-3.248s1.456-3.248 3.252-3.248c1.795.001 3.251 1.454 3.251 3.248zM0 8.18v4.811c6.05.062 10.96 4.966 11.022 11.009h4.817c-.062-8.71-7.118-15.758-15.839-15.82zm0-3.368c10.58.046 19.152 8.594 19.183 19.188H24c-.03-13.231-10.755-23.954-24-24v4.812z"/></svg></a><br><a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> &#183; Made with <a href="https://gohugo.io">Hugo</a></p></div></div><div class="masthead"><div class="container"><h3 class="masthead-title"><a href="https://ruddra.com/" title="Home" class="home-title">Ruddra</a><small class="home-title-small">.com</small></h3><form target="_top" class="masthead-search-form" method="get" action="/search/"><input type="text" aria-label="search" placeholder="Search ..." class="tftextinput" name="q" size="21" maxlength="120"><button type="submit" aria-label="search button" class="tfbutton"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="rgb(155,155,155)"><path d="M9.145 18.29c-5.042.0-9.145-4.102-9.145-9.145S4.103.0 9.145.0s9.145 4.103 9.145 9.145-4.102 9.145-9.145 9.145zm0-15.167c-3.321.0-6.022 2.702-6.022 6.022s2.702 6.022 6.022 6.022 6.023-2.702 6.023-6.022-2.702-6.022-6.023-6.022zm9.263 12.443c-.817 1.176-1.852 2.188-3.046 2.981l5.452 5.453 3.014-3.013-5.42-5.421z"/></svg></button></form></div></div><div class="container content"><div id="blog-post" class="post"><h1 class="post-title"><a href="https://ruddra.com/beginners-guide-on-scraping-using-python/">Beginner's Guide on Web Scraping using Python</a></h1><span class="post-date">Nov 12, 2020 &#183; 7 Min Read &#183; 8 Likes &#183; 0 Comment</span><div class="img-container"><img class="lozad" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0MTE1IDI3MzkiLz4=" data-srcset="/content/images/2020/11/crawling_huc911eb17170b9603d91673ade8c59b24_1075136_220x0_resize_q100_box.jpg 220w,/content/images/2020/11/crawling_huc911eb17170b9603d91673ade8c59b24_1075136_440x0_resize_q100_box.jpg 440w,/content/images/2020/11/crawling_huc911eb17170b9603d91673ade8c59b24_1075136_500x0_resize_q100_box.jpg 500w,/content/images/2020/11/crawling_huc911eb17170b9603d91673ade8c59b24_1075136_600x0_resize_q100_box.jpg 600w,/content/images/2020/11/crawling_huc911eb17170b9603d91673ade8c59b24_1075136_720x0_resize_q100_box.jpg 720w" alt="Beginner's Guide on Web Scraping using Python" data-sizes="440w"><noscript><img src="/content/images/2020/11/crawling.jpg" width="4115" height="2739" alt="Beginner's Guide on Web Scraping using Python"></noscript></div><div class="photo-credit"><span>Photo by <a href="https://unsplash.com/@rayhennessy?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Ray Hennessy</a> on <a href="https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a></span></div><div><p>When it comes to web scraping, you have to keep in mind that it is not the coding skill rather cunning observations will get you results. Sometimes the data you get comes in a straight forward way, other times the website does not want you to crawl itself. Either way you will get the data, but it takes time depending on how many puzzles do you have to solve before getting it. Here are some tips to resolve these puzzles and code snippets to give you some heads up.</p><div class="toc"><input id="_toc" type="checkbox" name="_toc"><label class="collapse" for="_toc">Table of contents&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-down"><polyline class="chevron-down" points="6 10 14 18 22 10"/><polyline class="chevron-up" points="22 18 14 10 6 18"/></svg></label><nav id="TableOfContents"><ul><li><a href="#beautifulsoup-and-requests-are-your-friend"><code>BeautifulSoup</code> and <code>requests</code> are your friend</a></li><li><a href="#avoid-crawling-if-there-is-an-api">Avoid crawling if there is an API</a></li><li><a href="#use-regex-to-bend-the-knee">Use Regex to bend the knee</a></li><li><a href="#look-for-api-calls-in-using-developer-tool">Look for API calls in using developer tool</a></li><li><a href="#use-map-filter-functions">Use <code>map</code>, <code>filter</code> functions</a></li><li><a href="#if-there-is-an-excel-or-csv-file-you-are-in-luck">If there is an excel or csv file, you are in luck</a></li><li><a href="#you-can-get-data-from-pdf-as-well">You can get data from PDF as well</a></li><li><a href="#mimic-actions-like-login-or-form-submission">Mimic actions like login or form submission</a></li><li><a href="#need-more-robust-solution-then-use-scrapy">Need more robust solution, then use <code>Scrapy</code></a></li><li><a href="#selenium-is-the-last-resort"><code>Selenium</code> is the last resort</a></li><li><a href="#in-conclusion">In conclusion</a></li></ul></nav></div><h2 id="beautifulsoup-and-requests-are-your-friend"><code>BeautifulSoup</code> and <code>requests</code> are your friend<a href="#beautifulsoup-and-requests-are-your-friend" class="hanchor" aria-label="Anchor"> <svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>&#xFE0E;</a></h2><p><a href="https://requests.readthedocs.io/en/master/"><code>requests</code></a> is the best library in python for making http requests. You can get the html data as a response from any website. Then you can purse the html data using <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">Beautiful Soap(aka <code>BS4</code>)</a>. Here is an example to get all the links from <a href="https://wikipedia.com">Wikipedia</a> front page:</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;https://wikipedia.com&#34;</span><span class="p">)</span>
<span class="n">soap</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">soap</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">])</span>
</code></pre></div><p>Majority of websites can be scrapped by these two libraries. A web scrapers best friends 😄.</p><h2 id="avoid-crawling-if-there-is-an-api">Avoid crawling if there is an API<a href="#avoid-crawling-if-there-is-an-api" class="hanchor" aria-label="Anchor"> <svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>&#xFE0E;</a></h2><p>As said above, scraping data from the majority of websites is simple but we are not talking about Facebook or Twitter here because these websites don&rsquo;t allow scraping or it may be illegal. Instead, you should look for APIs to get the needed data. So before scraping, try looking for API documentation of any site, and if it is an RESTful API, then use <code>requests</code> library to get the data. You can use other libraries such as <code>BS</code> for SOAP API etc.</p><p>There is another reason to avoid scraping, that is the website changes time to time. The layout may change, or the url may change. It will make the crawler fail or need to rework from time to time. So it is better to use API if there is any. Here is an example from Wikipedia API documentation:</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>

<span class="n">revision_id</span> <span class="o">=</span> <span class="s1">&#39;764138197&#39;</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://en.wikipedia.org/w/rest.php/v1/revision/&#39;</span> <span class="o">+</span> <span class="n">revision_id</span> <span class="o">+</span> <span class="s1">&#39;/bare&#39;</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;MediaWiki REST API docs examples/0.1 (https://www.mediawiki.org/wiki/API_talk:REST_API)&#39;</span><span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div><h2 id="use-regex-to-bend-the-knee">Use Regex to bend the knee<a href="#use-regex-to-bend-the-knee" class="hanchor" aria-label="Anchor"> <svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>&#xFE0E;</a></h2><p>Sometimes the data is plain in the open but you can&rsquo;t grab it because you do not know how to distinguish the html element. For example, you want to see all the species and their urls from Macaw wikipedia page, but there are lots of links you do need. Then, simply use regex to determine them:</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;https://en.wikipedia.org/wiki/Macaw&#34;</span><span class="p">)</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">href</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;.*macaw&#39;</span><span class="p">)))</span>  <span class="c1"># regex to get urls end with macaw</span>
</code></pre></div><h2 id="look-for-api-calls-in-using-developer-tool">Look for API calls in using developer tool<a href="#look-for-api-calls-in-using-developer-tool" class="hanchor" aria-label="Anchor"> <svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>&#xFE0E;</a></h2><p>Dynamic websites usually use API calls to get the content from the backend. You can look for these calls and use them to get data. Here is an example, if you go to the search bar on Wikipedia website, type something and open inspect element or any other developer tool. Then go to the network section and click on the XHR tab/checkbox, you should see the RESTful API calls it is making to get the data. Use the <code>requests</code> library to get them.</p><div class="page-img-container"><img class="lozad page-image" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA4NjIgMzEzIi8+" data-src="/content/images/2020/11/inspect_element_hu5d4d4af13a53f9dee6df2227e73445ae_54027_500x0_resize_q100_box.jpg" data-srcset="/content/images/2020/11/inspect_element_hu5d4d4af13a53f9dee6df2227e73445ae_54027_500x0_resize_q100_box.jpg 500w,/content/images/2020/11/inspect_element_hu5d4d4af13a53f9dee6df2227e73445ae_54027_600x0_resize_q100_box.jpg 600w,/content/images/2020/11/inspect_element_hu5d4d4af13a53f9dee6df2227e73445ae_54027_720x0_resize_q100_box.jpg 720w" alt="ReactJS Inspect element" data-sizes="440w"><noscript><img src="/content/images/2020/11/inspect_element.jpg" width="862" height="313" alt="ReactJS Inspect element"></noscript></div><p>Here is a sample code to call the API:</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&#34;https://en.wikipedia.org/w/api.php?action=opensearch&amp;format=json&amp;formatversion=2&amp;search=leonardo&amp;namespace=0&amp;limit=10&#34;</span>
<span class="k">print</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</code></pre></div><h2 id="use-map-filter-functions">Use <code>map</code>, <code>filter</code> functions<a href="#use-map-filter-functions" class="hanchor" aria-label="Anchor"> <svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>&#xFE0E;</a></h2><p><code>map</code>, <code>filter</code> are extremely powerful functions in Python. Using them, you can drastically reduce codes and clean up your data. Suppose you want to get data from <a href="https://en.wikipedia.org/wiki/Django_(web_framework)">Django&rsquo;s Wiki page</a>, specifically you want to get version numbers from the releases table. The table looks like this:</p><div class="page-img-container"><img class="lozad page-image" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxNTYyIDE3NTQiLz4=" data-src="/content/images/2020/11/wiki_django_hu7fba9da1679ce4a56c592454604cb9c1_557162_500x0_resize_q100_box.jpg" data-srcset="/content/images/2020/11/wiki_django_hu7fba9da1679ce4a56c592454604cb9c1_557162_500x0_resize_q100_box.jpg 500w,/content/images/2020/11/wiki_django_hu7fba9da1679ce4a56c592454604cb9c1_557162_600x0_resize_q100_box.jpg 600w,/content/images/2020/11/wiki_django_hu7fba9da1679ce4a56c592454604cb9c1_557162_720x0_resize_q100_box.jpg 720w" alt="django wiki" data-sizes="440w"><noscript><img src="/content/images/2020/11/wiki_django.jpg" width="1562" height="1754" alt="django wiki"></noscript></div><p>Let us get the table from that page:</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&#34;https://en.wikipedia.org/wiki/Django_(web_framework)&#34;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">soap</span> <span class="o">=</span> <span class="n">BeautifulSoap</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">soap</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;table&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;class&#39;</span><span class="p">:</span> <span class="s1">&#39;wikitable&#39;</span><span class="p">})</span>
</code></pre></div><p>Now we can fetch the values from table</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">values</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;tbody&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;tr&#39;</span><span class="p">)</span>
</code></pre></div><p>But as you can see, all the values of the table are not versions. Let us use <code>map</code> function to get the versions only. We know that the first column of a row is the versions column, and we can get it via <code>.find()</code> function of <code>bs4</code>.</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">values</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;td&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;span&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
</code></pre></div><p>Now we have all the html elements from the version column. But we do not need data from the rows which do not contain any information. Time to clean it up via filter function:</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">values</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">!=</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;data-sort-value&#39;</span><span class="p">),</span> <span class="n">values</span><span class="p">)</span>
</code></pre></div><p>We are almost ready, a final <code>map</code> function to get the value from each row and print it.</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;data-sort-value&#39;</span><span class="p">),</span> <span class="n">values</span><span class="p">)))</span>
</code></pre></div><p>A nice thing about using <code>filter</code> and <code>map</code> is that, they are generators; they do not hold up memory unless you execute it. Meaning until we called <code>list()</code> method, it was not taking any space at all.</p><h2 id="if-there-is-an-excel-or-csv-file-you-are-in-luck">If there is an excel or csv file, you are in luck<a href="#if-there-is-an-excel-or-csv-file-you-are-in-luck" class="hanchor" aria-label="Anchor"> <svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>&#xFE0E;</a></h2><p>If somehow you get a hold of CSV or excel data from a website, then you are lucky. If it is a CSV, then simply <code>csv</code> library from python:</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://dumps.wikimedia.org/other/pagecounts-ez/wikistats/SquidDataVisitsPerCountryDaily.csv&#39;</span>

<span class="n">cr</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">decode</span><span class="p">(),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">cr</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
</code></pre></div><p>If you have excel file, then use <a href="https://xlrd.readthedocs.io/en/latest/"><code>xlrd</code></a>:</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">xlrd</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&#34;https://wiki.openoffice.org/w/images/f/ff/Sample_Spreadsheet_format_all.xls&#34;</span>
<span class="n">book</span> <span class="o">=</span> <span class="n">xlrd</span><span class="o">.</span><span class="n">open_workbook</span><span class="p">(</span><span class="n">file_content</span><span class="o">=</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">book</span><span class="o">.</span><span class="n">sheet_names</span><span class="p">())</span>
</code></pre></div><p>BTW, <a href="https://pandas.pydata.org">pandas</a> provides excellent support for getting data from csv and excel files. Please checkout their documentation.</p><h2 id="you-can-get-data-from-pdf-as-well">You can get data from PDF as well<a href="#you-can-get-data-from-pdf-as-well" class="hanchor" aria-label="Anchor"> <svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>&#xFE0E;</a></h2><p>You can scrape data from <strong>PDF</strong>s as well. You can use a library called <a href="https://github.com/jalan/pdftotext"><code>pdftotext</code></a> library which uses <code>poppler</code> to extract texts from PDF. But keep in mind that the data coming from PDFs are in plain text, it is really hard to identify what data you want to scrap. It is better to use regex to find data. For example:</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pdftotext</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&#34;https://upload.wikimedia.org/wikipedia/commons/e/ef/Sample_Syllabus_for_Wikipedia_assignment.pdf&#34;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="n">pdf</span> <span class="o">=</span> <span class="n">pdftotext</span><span class="o">.</span><span class="n">PDF</span><span class="p">(</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">))</span>
<span class="n">text</span> <span class="o">=</span> <span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n\n</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pdf</span><span class="p">))</span>
</code></pre></div><h2 id="mimic-actions-like-login-or-form-submission">Mimic actions like login or form submission<a href="#mimic-actions-like-login-or-form-submission" class="hanchor" aria-label="Anchor"> <svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>&#xFE0E;</a></h2><p>You can easily mimic html form submission or actions like login using <code>requests</code>. Lets say, you want to submit a form on a certain website. First, use the inspect element/developer tool by browser to see what kind requests are made to the server. Probably it will be a POST request. Now see the payload, headers and url. Now use it in <code>requests</code>:</p><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&#34;https://example.com&#34;</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/x-www-form-urlencoded&#39;</span><span class="p">,</span>
    <span class="s2">&#34;User-Agent&#34;</span><span class="p">:</span><span class="s2">&#34;Mozilla/5.0&#34;</span>
<span class="p">}</span>

<span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&#34;username&#34;</span><span class="p">:</span> <span class="s2">&#34;username&#34;</span><span class="p">,</span>
    <span class="s2">&#34;password&#34;</span><span class="p">:</span> <span class="s2">&#34;password&#34;</span>
<span class="p">}</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;{url}/login&#34;</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">payload</span><span class="p">)</span>

<span class="c1"># Now you are logged in, let us get /profile page</span>

<span class="n">resp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;{url}/profile&#34;</span><span class="p">)</span>
</code></pre></div><h2 id="need-more-robust-solution-then-use-scrapy">Need more robust solution, then use <code>Scrapy</code><a href="#need-more-robust-solution-then-use-scrapy" class="hanchor" aria-label="Anchor"> <svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>&#xFE0E;</a></h2><p>Some servers have mechanisms to prevent DDOS attacks or prevent multiple hits from a single IP. So it is better to not hit those websites in a limited interval. You can use <a href="https://scrapy.org"><code>Scrapy</code></a> like solution which allows hitting from multiple IPs. They also provide ways to run multiple scrapping jobs and make the scraping process faster.</p><h2 id="selenium-is-the-last-resort"><code>Selenium</code> is the last resort<a href="#selenium-is-the-last-resort" class="hanchor" aria-label="Anchor"> <svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>&#xFE0E;</a></h2><p>You should consider <a href="https://selenium-python.readthedocs.io"><code>Selenium</code></a> as a last resort. If you can&rsquo;t crawl the website anyhow, then use Selenium. But probably you can&rsquo;t scrap Facebook or Twitter like websites using it.</p><h2 id="in-conclusion">In conclusion<a href="#in-conclusion" class="hanchor" aria-label="Anchor"> <svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>&#xFE0E;</a></h2><p>Scraping becomes necessary for collecting essential data which can be used on various purposes like Data Science. There are fantastic tools built using Python to help you with them. I hope this guideline will help you with getting started on scrapping. If you have any questions or opinions, please share in the comment section below. Cheers!!</p><p><strong>Last updated</strong>: Nov 13, 2020</p></div></div><hr><div class="miscellaneous"><ul class="side-share"><li class="like-comment"><span id="love-share"><svg class="love-share-sign" id="love-share-sign" fill="#d0d0d0" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M12 4.248c-3.148-5.402-12-3.825-12 2.944C0 11.853 5.571 16.619 12 23c6.43-6.381 12-11.147 12-15.808.0-6.792-8.875-8.306-12-2.944z"/></svg><span id="loved-count" class="loved-count">x<span id="like-count">8</span></span></span></li><li class="like-comment"><svg class="comment-sign" id="show-comment-btn" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="#d0d0d0"><path d="M24 10.162c0-5.06-5.373-9.162-12-9.162S0 5.102.0 10.162c0 5.097 5.447 9.213 12.121 9.161-.391 2.015-2.765 3.275-4.545 3.677 10.109-.89 16.424-6.489 16.424-12.838z"/></svg><span id="loved-count" class="comment-count">x<span id="comment-counter">0<span></span></span></span></li><input type="checkbox" id="_show_social_share"><li class="share-button"><label id="show-hide-share" class="collapse-share" for="_show_social_share"><svg class="share-sign" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="#d0d0d0"><path d="M5 7c2.761.0 5 2.239 5 5s-2.239 5-5 5-5-2.239-5-5 2.239-5 5-5zm11.122 12.065c-.073.301-.122.611-.122.935.0 2.209 1.791 4 4 4s4-1.791 4-4-1.791-4-4-4c-1.165.0-2.204.506-2.935 1.301l-5.488-2.927c-.23.636-.549 1.229-.943 1.764l5.488 2.927zm7.878-15.065c0-2.209-1.791-4-4-4s-4 1.791-4 4c0 .324.049.634.122.935l-5.488 2.927c.395.535.713 1.127.943 1.764l5.488-2.927c.731.795 1.77 1.301 2.935 1.301 2.209.0 4-1.791 4-4z"/></svg><svg fill="#515151" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M5 9c1.654.0 3 1.346 3 3s-1.346 3-3 3-3-1.346-3-3 1.346-3 3-3zm0-2c-2.762.0-5 2.239-5 5s2.238 5 5 5 5-2.239 5-5-2.238-5-5-5zm15 9c-1.165.0-2.204.506-2.935 1.301l-5.488-2.927c-.23.636-.549 1.229-.944 1.764l5.488 2.927c-.072.301-.121.611-.121.935.0 2.209 1.791 4 4 4s4-1.791 4-4-1.791-4-4-4zm0 6c-1.103.0-2-.897-2-2s.897-2 2-2 2 .897 2 2-.897 2-2 2zm0-22c-2.209.0-4 1.791-4 4 0 .324.049.634.121.935l-5.488 2.927c.395.536.713 1.128.944 1.764l5.488-2.927c.731.795 1.77 1.301 2.935 1.301 2.209.0 4-1.791 4-4s-1.791-4-4-4zm0 6c-1.103.0-2-.897-2-2s.897-2 2-2 2 .897 2 2-.897 2-2 2z"/></svg></label></li><li class="social-share"><a target="_blank" aria-label="FB" rel="noreferrer" href="https://www.facebook.com/dialog/share?app_id=668971647169067&display=page&href=https%3a%2f%2fruddra.com%2fbeginners-guide-on-scraping-using-python%2f&redirect_uri=https%3a%2f%2fruddra.com%2fbeginners-guide-on-scraping-using-python%2f"><svg class="fb-share-sign" fill="#515151" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M9 8H6v4h3v12h5V12h3.642L18 8h-4V6.333C14 5.378 14.192 5 15.115 5H18V0h-3.808C10.596.0 9 1.583 9 4.615V8z"/></svg></a></li><li class="social-share"><a aria-label="Twitter" target="_blank" rel="noreferrer" href="https://twitter.com/intent/tweet?text=Beginner%27s%20Guide%20on%20Web%20Scraping%20using%20Python&url=https%3a%2f%2fruddra.com%2fbeginners-guide-on-scraping-using-python%2f"><svg class="tw-share-sign" fill="#515151" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M24 4.557c-.883.392-1.832.656-2.828.775 1.017-.609 1.798-1.574 2.165-2.724-.951.564-2.005.974-3.127 1.195-.897-.957-2.178-1.555-3.594-1.555-3.179.0-5.515 2.966-4.797 6.045-4.091-.205-7.719-2.165-10.148-5.144-1.29 2.213-.669 5.108 1.523 6.574-.806-.026-1.566-.247-2.229-.616-.054 2.281 1.581 4.415 3.949 4.89-.693.188-1.452.232-2.224.084.626 1.956 2.444 3.379 4.6 3.419-2.07 1.623-4.678 2.348-7.29 2.04 2.179 1.397 4.768 2.212 7.548 2.212 9.142.0 14.307-7.721 13.995-14.646.962-.695 1.797-1.562 2.457-2.549z"/></svg></a></li><li class="social-share"><a aria-label="LN" target="_blank" rel="noreferrer" href="https://www.linkedin.com/shareArticle/?mini=true&url=https%3a%2f%2fruddra.com%2fbeginners-guide-on-scraping-using-python%2f&title=Beginner%27s%20Guide%20on%20Web%20Scraping%20using%20Python&summary=&source="><svg class="ln-share-sign" fill="#515151" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M4.98 3.5c0 1.381-1.11 2.5-2.48 2.5s-2.48-1.119-2.48-2.5c0-1.38 1.11-2.5 2.48-2.5s2.48 1.12 2.48 2.5zM5 8H0v16h5V8zm7.982.0H8.014v16h4.969v-8.399c0-4.67 6.029-5.052 6.029.0V24H24V13.869c0-7.88-8.922-7.593-11.018-3.714V8z"/></svg></a></li></ul><div class="tags"><a class="tag-links-a" href="/tags/python/">Python</a> <a class="tag-links-a" href="/tags/scraping/">Scraping</a></div></div><div class="newsletter-section" id="newsletter-submitted"><h2 class="newsletter-header">Get Better With Python</h2><div id="commento-newsletter" class="commento-root commento-root-font"><div id="newsletter-error" class="commento-error-box" style="display:none">An error occurred when submitting the form, please try again.</div><div id="newsletter-submitted-box" style="display:none"><p class="newsletter-submitted-txt">Thank you for your subscription to our newsletters.<br>You will start receiving emails from next iteration.</p></div><div id="newsletter-body"><div class="newsletter-txt">Subscribe to get monthly articles about Python and more.<br>I won't spam you. Unsubscribe at any time.</div><div id="commento-main-area-newsletter" class="commento-main-area"><form id="commento-form" method="post" action="https://ruddra-comments.netlify.app/.netlify/functions/server/v2/entry/ruddra/ruddra.comments/master/comments"><input type="hidden" name="options[redirect]" value="https://ruddra.com/beginners-guide-on-scraping-using-python/#newsletter-submitted"> <input type="hidden" name="options[slug]" value="newsletter-subscription"> <input type="hidden" name="options[parent]" value="newsletter-subscription"> <input type="hidden" name="options[origin]" value="https://ruddra.com/newsletters/"> <input type="hidden" name="options[redirectError]" value="https://ruddra.com/beginners-guide-on-scraping-using-python/#newsletter-error"><div id="commento-login" class="commento-login"><label id="email-newsletter"><input aria-label="My email address is ..." type="email" name="fields[email]" placeholder="My email address is ..." style="padding-left:10px;width:90%;line-height:2;border:1px solid rgba(50,50,93,.1)" required></label></div><div style="width:95.8%"><button id="commento-submit-button-root-newsletter" type="submit" class="commento-button commento-submit-button">Subscribe</button><div class="commento-round-check commento-anonymous-checkbox-container"><input id="commento-checkbox-root" name="options[subscribe]" type="checkbox" value="email" required><label for="commento-checkbox-root">I agree to receive emails</label></div></div></form></div></div></div></div><div class="pagination"><div class="pagination-item older"><span class="pagination-arrow">&#8592; Previous</span><div class="pagination-link"><a href="https://ruddra.com/hugo-get-perfect-pagespeed-score/">Hugo: Get (Almost) Perfect Score in Google PageSpeed …</a></div><div class="pagination-image"><img class="lozad" data-src="/content/images/2020/07/perfect_hu829c312439b0496477cded50cc2d9b0d_3458557_350x0_resize_q100_box.jpg" alt="Hugo: Get (Almost) Perfect Score in Google PageSpeed Insights"><noscript><img src="/content/images/2020/07/perfect_hu829c312439b0496477cded50cc2d9b0d_3458557_350x0_resize_q100_box.jpg" alt="Hugo: Get (Almost) Perfect Score in Google PageSpeed Insights"></noscript></div><p class="pagination-text">You will see many Hugo themes boast perfect scores on Google PageSpeed Insights(PSI). To be honest, …</p></div><div class="pagination-item newer"><span class="pagination-arrow">Next &#8594;</span><div class="pagination-link"><a href="https://ruddra.com/django-translation-using-po-file/">Django Translation Using .PO File</a></div><div class="pagination-image"><img class="lozad" data-src="/content/images/2020/04/translation_hueef3f3081fa056706344f4f0519cbeae_664337_350x0_resize_q100_box.jpg" alt="Django Translation Using .PO File"><noscript><img src="/content/images/2020/04/translation_hueef3f3081fa056706344f4f0519cbeae_664337_350x0_resize_q100_box.jpg" alt="Django Translation Using .PO File"></noscript></div><p class="pagination-text">This post is deprecated. Please follow the official documentation. When comes to using multiple …</p></div></div><div class="tiny" id="comment-submitted"><div id="commento" class="commento-root commento-root-font"><div id="comment-submitted-box" style="display:none">Thank you for your comment. It will be published shortly.</div><div id="comment-error" style="display:none">An error occurred when submitting the form, please try again.</div><div id="commento-main-area" class="commento-main-area"><div class="commento-name" id="comment-headline"><b>Share Your Thoughts</b></div><form id="comment-form" method="post" name="comment-form"><input type="hidden" name="options[redirect]" value="https://ruddra.com/beginners-guide-on-scraping-using-python/#comment-submitted"> <input type="hidden" name="options[slug]" value="beginners-guide-on-scraping-using-python"> <input type="hidden" name="options[parent]" value="beginners-guide-on-scraping-using-python"> <input type="hidden" name="options[origin]" value="https://ruddra.com/beginners-guide-on-scraping-using-python/"> <input type="hidden" id="comment-parent" name="fields[reply_to]"> <input type="hidden" name="options[redirectError]" value="https://ruddra.com/beginners-guide-on-scraping-using-python/#comment-error"> <textarea name="fields[comment]" id="commento-textarea-root" placeholder="Add a comment" required aria-label="Add a comment"></textarea> <button id="commento-submit-button-root" type="submit" class="commento-button commento-submit-button submit-github">Comment With Github</button><div class="commento-round-check commento-anonymous-checkbox-container"><input id="commento-anonymous-checkbox-root" name="options[subscribe]" type="checkbox" value="email"><label for="commento-anonymous-checkbox-root">Notify me of new comments</label></div><a onclick="toggleMarkDownTable()" id="commento-markdown-button-root" class="commento-markdown-button"><b>M↓</b> <span class="commento-markdown">Markdown</span></a><table id="commento-markdown-help-root" class="commento-markdown-help" style="display:none"><tr><td><i>italics</i></td><td>surround text with<code>*asterisks*</code></td></tr><tr><td><b>bold</b></td><td>surround text with<code>**two asterisks**</code></td></tr><tr><td><a href="https://example.com">hyperlink</a></td><td><code>[hyperlink](https://example.com)</code> or just a bare URL</td></tr><tr><td><code>code</code></td><td>surround text with <code>`backticks`</code></td></tr><tr><td><code>code block</code></td><td>surround text with <code>```console.log()```</code></td></tr><tr><td><strike>strikethrough</strike></td><td>surround text with <code>~~two tilde characters~~</code></td></tr><tr><td><blockquote>quote</blockquote></td><td>prefix with <code>></code></td></tr><tr><td>Emoji 😱</td><td><b>:smile:</b>😄 <b>:angry:</b>😠 <b>:disappointed:</b>😞(<a href="https://www.webfx.com/tools/emoji-cheat-sheet/">cheat sheet</a>)</td></tr></table></form></div></div></div></div><label for="sidebar-checkbox" class="sidebar-toggle"></label><script src="/js/bundle1.min.78c0bdad978fe83d0f0ce27a8e61cf8cc1b5acfccc2a9b20bcd3e1bc610e9e68.js" defer="defer"></script><script>if("serviceWorker"in navigator){navigator.serviceWorker.register('/sw.js').then(reg=>{reg.installing;reg.waiting;reg.active;reg.addEventListener('updatefound',function(){reg.installing;});});};</script></body></html>